#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""æµ‹è¯•ç¿»è¯‘åŠŸèƒ½çš„è„šæœ¬

æ­¤è„šæœ¬ç”¨äºæµ‹è¯•DeepSeek APIçš„ç¿»è¯‘åŠŸèƒ½ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨404é”™è¯¯å’Œé…ç½®é—®é¢˜ã€‚
"""

import os
import sys
from dotenv import load_dotenv

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# æ‰“å°å½“å‰ç¯å¢ƒå˜é‡é…ç½®ï¼Œç”¨äºè°ƒè¯•
def print_config_info():
    """æ‰“å°å½“å‰çš„é…ç½®ä¿¡æ¯"""
    print("=== é…ç½®ä¿¡æ¯ ===")
    print(f"API_KEY: {os.getenv('API_KEY')}")
    print(f"BASE_URL: {os.getenv('BASE_URL')}")
    print(f"OPENAI_BASE_URL: {os.getenv('OPENAI_BASE_URL')}")
    print(f"DEEPSEEK_API_KEY: {os.getenv('DEEPSEEK_API_KEY')}")
    print("=== ä»£ç†ç¯å¢ƒå˜é‡ ===")
    proxy_keys = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']
    for key in proxy_keys:
        value = os.getenv(key, 'æœªè®¾ç½®')
        print(f"{key}: {value}")
    print("="*30)

# ä¿®å¤openai_llm.pyæ–‡ä»¶ä¸­çš„å¯¼å…¥é—®é¢˜
def fix_openai_llm_import():
    """ä¿®å¤openai_llm.pyæ–‡ä»¶ä¸­ç¼ºå°‘osæ¨¡å—å¯¼å…¥çš„é—®é¢˜"""
    llm_file_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "openai_llm.py")
    
    try:
        with open(llm_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥æ˜¯å¦å·²å¯¼å…¥osæ¨¡å—
        if 'import os' not in content:
            # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ osæ¨¡å—å¯¼å…¥
            new_content = "import os\n" + content
            
            with open(llm_file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            print(f"å·²ä¿®å¤ {llm_file_path} ä¸­çš„osæ¨¡å—å¯¼å…¥é—®é¢˜")
        else:
            print("openai_llm.py ä¸­å·²å¯¼å…¥osæ¨¡å—")
        
        return True
    except Exception as e:
        print(f"ä¿®å¤openai_llm.pyæ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

# æµ‹è¯•ç¿»è¯‘åŠŸèƒ½
def test_translation():
    """æµ‹è¯•ç¿»è¯‘åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    try:
        # å°è¯•å¯¼å…¥ç¿»è¯‘å‡½æ•°
        from utils import translate_to_english, auto_translate_if_needed
        
        # æµ‹è¯•æ–‡æœ¬
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç¿»è¯‘åŠŸèƒ½çš„ç¤ºä¾‹æ–‡æœ¬ã€‚"
        
        print(f"åŸå§‹æ–‡æœ¬: {test_text}")
        
        # æµ‹è¯•translate_to_englishå‡½æ•°
        print("\næµ‹è¯•translate_to_englishå‡½æ•°:")
        translated_text = translate_to_english(test_text)
        print(f"ç¿»è¯‘ç»“æœ: {translated_text}")
        
        # æµ‹è¯•auto_translate_if_neededå‡½æ•°
        print("\næµ‹è¯•auto_translate_if_neededå‡½æ•°:")
        auto_translated = auto_translate_if_needed(test_text)
        print(f"è‡ªåŠ¨ç¿»è¯‘ç»“æœ: {auto_translated}")
        
        # æµ‹è¯•ä½¿ç”¨è‹±æ–‡æ–‡æœ¬ï¼ˆä¸åº”ç¿»è¯‘ï¼‰
        print("\næµ‹è¯•è‹±æ–‡æ–‡æœ¬ï¼ˆä¸åº”ç¿»è¯‘ï¼‰:")
        english_text = "This is an English test text."
        non_translated = auto_translate_if_needed(english_text)
        print(f"åŸå§‹è‹±æ–‡: {english_text}")
        print(f"ç¿»è¯‘ç»“æœ: {non_translated}")
        
        return True
    except Exception as e:
        print(f"ç¿»è¯‘æµ‹è¯•å¤±è´¥: {str(e)}")
        # å°è¯•è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        import traceback
        print("é”™è¯¯è¯¦æƒ…:")
        traceback.print_exc()
        return False

# æµ‹è¯•LLMå®¢æˆ·ç«¯è¿æ¥
def test_llm_connection():
    """ç›´æ¥æµ‹è¯•LLMå®¢æˆ·ç«¯è¿æ¥"""
    try:
        from openai_llm import LLM
        
        print("\næµ‹è¯•LLMå®¢æˆ·ç«¯è¿æ¥:")
        llm = LLM()
        print(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {llm.model}")
        
        # ç®€å•çš„æµ‹è¯•æ¶ˆæ¯
        messages = [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚"}
        ]
        
        print("å‘é€æµ‹è¯•æ¶ˆæ¯...")
        response = llm.chat(messages)
        print(f"å“åº”æˆåŠŸ: {response['choices'][0]['message']['content']}")
        
        return True
    except Exception as e:
        print(f"LLMå®¢æˆ·ç«¯è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

# ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•°"""
    print("===== DeepSeek API ç¿»è¯‘åŠŸèƒ½æµ‹è¯• ======")
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print_config_info()
    
    # ä¿®å¤openai_llm.pyä¸­çš„å¯¼å…¥é—®é¢˜
    fix_openai_llm_import()
    
    # æµ‹è¯•ç¿»è¯‘åŠŸèƒ½
    print("\n===== å¼€å§‹æµ‹è¯•ç¿»è¯‘åŠŸèƒ½ =====")
    translation_success = test_translation()
    
    # æµ‹è¯•LLMå®¢æˆ·ç«¯è¿æ¥
    print("\n===== å¼€å§‹æµ‹è¯•LLMå®¢æˆ·ç«¯è¿æ¥ =====")
    connection_success = test_llm_connection()
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\n===== æµ‹è¯•æ€»ç»“ =====")
    print(f"ç¿»è¯‘åŠŸèƒ½æµ‹è¯•: {'æˆåŠŸ' if translation_success else 'å¤±è´¥'}")
    print(f"LLMå®¢æˆ·ç«¯è¿æ¥æµ‹è¯•: {'æˆåŠŸ' if connection_success else 'å¤±è´¥'}")
    
    if translation_success and connection_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¿»è¯‘åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("\nâŒ æµ‹è¯•æœªå…¨éƒ¨é€šè¿‡ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")
        
        # æä¾›å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š")
        print("1. ç¡®ä¿.envæ–‡ä»¶ä¸­çš„DEEPSEEK_API_KEYå’ŒOPENAI_BASE_URLé…ç½®æ­£ç¡®")
        print("2. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼Œç‰¹åˆ«æ˜¯æ˜¯å¦èƒ½è®¿é—®DeepSeek API")
        print("3. ç¡®è®¤APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ")

if __name__ == "__main__":
    main()